{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CircleCI for CI Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate, load_prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers.json import SimpleJsonOutputParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL_PROMPT_FILE_NAME: str = \"CALL_PROMPT.yaml\"\n",
    "CALL_SUMMARIZATION_PROMPT_FILENAME: str = \"SUMMARIZATION_PROMPT.yaml\"\n",
    "DEFAULT_OPENAI_MODEL_NAME: str =   \"gpt-3.5-turbo\"\n",
    "#\"gpt-4-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL_PROMPT = \"\"\" \n",
    "\n",
    "Role: As a Language Model Assistant in an ambulance healthcare setting, your role is to assist with predicting call categories by accurately analyzing patient call transcripts to expedite the triage process.\n",
    "    Vision:  You are extracting key information based on the Patient transcripts.\n",
    "    Mission: Provide concise, relevant, and clear summaries of patient issues based on the patient transcripts, ensuring that they are classified appropriately and directed to the correct team for immediate attention. \n",
    "\n",
    "    While answering, for Severity Levels, you can choose a severity based on the context below:\n",
    "\n",
    "    Low Severity:\n",
    "        - Genito-Urinary conditions\n",
    "        - Dental problem\n",
    "        - Failed contraception\n",
    "        - Palliative Care\n",
    "        - Suicidal\n",
    "    Medium Severity:\n",
    "        - Level 2 interfacility transfer\n",
    "        - Acute coronary syndrome\n",
    "        - Refused Ambulance disposition\n",
    "        - Potential Broken Arm/Leg\n",
    "        - Covid symptoms with respiratory distress\n",
    "    High Severity:\n",
    "        - Major Blood Loss\n",
    "        - Fitting now\n",
    "        - Unconsciousness\n",
    "        - Anaphylaxis\n",
    "        - Cardiac arrest\n",
    "        \n",
    "    Provide the output in JSON format with the following keys:\n",
    "        - Issue: (string) - Brief description of the patient's concern.\n",
    "        - Issue Summary: (string, less than 20 words) - Concise overview of the problem.\n",
    "        - Severity: ( Low , Medium , High ) - Urgency of the patient's situation.\n",
    "        - Clinician to Contact: (general, support, technical) - If the transcript contains 3 or more “Not Sure” Keywords or “I don’t know” In it then output “Clinician to Contact Patient”\n",
    "    \n",
    "    Note: Before answering a question, ensure that the provided transcript is related to a reporting an issue or a similar scenario and not anything else apart from this. If not, then output 'Invalid' for all keys.\n",
    "\n",
    "    Transcript:\n",
    "    {Transcript}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SUMMARIZATION_PROMPT = \\\n",
    "\"\"\"Please summarize the following text, capturing the key points and main concerns expressed in less than 10 words:\n",
    "\n",
    "{Transcript}\n",
    "\n",
    "Make sure to include relevant details, such as symptoms, background information, current situations, and any specific requests or questions posed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_API_KEY'] = \"\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompt(template: str, input_variables: list, file_name: str):\n",
    "    \"\"\"\n",
    "    Save a prompt template to a file and then load it back.\n",
    "\n",
    "    Args:\n",
    "        template (str): The template string for the prompt.\n",
    "        input_variables (list): List of input variables used in the template.\n",
    "        file_name (str): The name of the file to save the prompt template to.\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=input_variables,\n",
    "    )\n",
    "\n",
    "    prompt.save(file_name)\n",
    "    print(f\"Prompt template saved to {file_name}\")\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template saved to CALL_PROMPT.yaml\n",
      "Prompt template saved to SUMMARIZATION_PROMPT.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_prompt(CALL_PROMPT, [], CALL_PROMPT_FILE_NAME)\n",
    "save_prompt(SUMMARIZATION_PROMPT, [], CALL_SUMMARIZATION_PROMPT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallDataProcessor:\n",
    "\n",
    "    def __init__(self, model_name, summarization_prompt_path, classifier_prompt_path):\n",
    "        self.summarization_prompt = load_prompt(summarization_prompt_path)\n",
    "        self.classifier_prompt = load_prompt(classifier_prompt_path)\n",
    "        self.model_name = model_name \n",
    "\n",
    "    def process_input(self, input_data):\n",
    "        try:\n",
    "\n",
    "\n",
    "            llm = ChatOpenAI(model=self.model_name, temperature=0)\n",
    "            llm_json = ChatOpenAI(model=self.model_name, temperature=0, model_kwargs={'response_format': {\"type\": \"json_object\"}})\n",
    "            \n",
    "            # Create the classifier and summary chains\n",
    "            classifier_chain = self.classifier_prompt | llm_json | SimpleJsonOutputParser()\n",
    "            classifier_result = classifier_chain.invoke(input_data)\n",
    "            \n",
    "            summary_chain = self.summarization_prompt | llm\n",
    "            summary_result = summary_chain.invoke(input_data).content\n",
    "            \n",
    "            # Structure the results\n",
    "            result = {\n",
    "                \"Transcript\": input_data,\n",
    "                \"Summary\": summary_result,\n",
    "                \"Issue\": classifier_result['Issue'],\n",
    "                \"Issue Summary\": classifier_result['Issue Summary'],\n",
    "                \"Severity\": classifier_result['Severity'],\n",
    "                \"Clinician to Contact\": classifier_result['Clinician to Contact']\n",
    "            }\n",
    "        \n",
    "            return result\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_prompt_path= CALL_PROMPT_FILE_NAME\n",
    "summarization_prompt_path = CALL_SUMMARIZATION_PROMPT_FILENAME\n",
    "\n",
    "processor = CallDataProcessor(DEFAULT_OPENAI_MODEL_NAME, summarization_prompt_path, classifier_prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Please hurry, she's unconscious on the floor! I tried checking her pulse, but there's nothing. We've already called 911, but she needs help now! I think she might have hit her head when she fell. Is there anything we can do while we wait for the ambulance?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Transcript': \"Please hurry, she's unconscious on the floor! I tried checking her pulse, but there's nothing. We've already called 911, but she needs help now! I think she might have hit her head when she fell. Is there anything we can do while we wait for the ambulance?\",\n",
       " 'Summary': 'Urgent situation: unconscious woman, no pulse, possible head injury.',\n",
       " 'Issue': 'Unconsciousness',\n",
       " 'Issue Summary': 'Patient is unconscious and unresponsive.',\n",
       " 'Severity': 'High',\n",
       " 'Clinician to Contact': 'Invalid'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_response = processor.process_input(input)\n",
    "\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Write Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "langchain\n",
    "langchain-community\n",
    "langchain-google-genai\n",
    "langchain-openai\n",
    "langchain-together\n",
    "\n",
    "numpy\n",
    "pandas\n",
    "\n",
    "pillow\n",
    "pydantic\n",
    "pydantic-settings\n",
    "python-dotenv\n",
    "python-multipart\n",
    "sentence-transformers\n",
    "starlette\n",
    "tiktoken\n",
    "uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting application.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile application.py\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate, load_prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers.json import SimpleJsonOutputParser \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Parameters\n",
    "\n",
    "CALL_PROMPT_FILE_NAME: str = \"CALL_PROMPT.yaml\"\n",
    "CALL_SUMMARIZATION_PROMPT_FILENAME: str = \"SUMMARIZATION_PROMPT.yaml\"\n",
    "DEFAULT_OPENAI_MODEL_NAME: str =   \"gpt-3.5-turbo\"\n",
    "#\"gpt-4-turbo\"\n",
    "\n",
    "\n",
    "# Prompts\n",
    "\n",
    "CALL_PROMPT = \"\"\" \n",
    "\n",
    "    Role: As a Language Model Assistant in an ambulance healthcare setting, your role is to assist with predicting call categories by accurately analyzing patient call transcripts to expedite the triage process.\n",
    "    Vision:  You are extracting key information based on the Patient transcripts.\n",
    "    Mission: Provide concise, relevant, and clear summaries of patient issues based on the patient transcripts, ensuring that they are classified appropriately and directed to the correct team for immediate attention. \n",
    "\n",
    "    While answering, for Severity Levels, you can choose a severity based on the context below:\n",
    "\n",
    "    Low Severity:\n",
    "        - Genito-Urinary conditions\n",
    "        - Dental problem\n",
    "        - Failed contraception\n",
    "        - Palliative Care\n",
    "        - Suicidal\n",
    "    Medium Severity:\n",
    "        - Level 2 interfacility transfer\n",
    "        - Acute coronary syndrome\n",
    "        - Refused Ambulance disposition\n",
    "        - Potential Broken Arm/Leg\n",
    "        - Covid symptoms with respiratory distress\n",
    "    High Severity:\n",
    "        - Major Blood Loss\n",
    "        - Fitting now\n",
    "        - Unconsciousness\n",
    "        - Anaphylaxis\n",
    "        - Cardiac arrest\n",
    "        \n",
    "    Provide the output in JSON format with the following keys:\n",
    "        - Issue: (string) - Brief description of the patient's concern.\n",
    "        - Issue Summary: (string, less than 20 words) - Concise overview of the problem.\n",
    "        - Severity: ( Low , Medium , High ) - Urgency of the patient's situation.\n",
    "        - Clinician to Contact: (general, support, technical) - If the transcript contains 3 or more “Not Sure” Keywords or “I don’t know” In it then output “Clinician to Contact Patient”\n",
    "    \n",
    "    Note: Before answering a question, ensure that the provided transcript is related to a reporting an issue or a similar scenario and not anything else apart from this. If not, then output 'Invalid' for all keys.\n",
    "\n",
    "    Transcript:\n",
    "    {Transcript}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SUMMARIZATION_PROMPT = \\\n",
    "\"\"\"Please summarize the following text, capturing the key points and main concerns expressed in less than 10 words:\n",
    "\n",
    "{Transcript}\n",
    "\n",
    "Make sure to include relevant details, such as symptoms, background information, current situations, and any specific requests or questions posed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "def save_prompt(template: str, input_variables: list, file_name: str):\n",
    "    \"\"\"\n",
    "    Save a prompt template to a file and then load it back.\n",
    "\n",
    "    Args:\n",
    "        template (str): The template string for the prompt.\n",
    "        input_variables (list): List of input variables used in the template.\n",
    "        file_name (str): The name of the file to save the prompt template to.\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=input_variables,\n",
    "    )\n",
    "\n",
    "    prompt.save(file_name)\n",
    "    print(f\"Prompt template saved to {file_name}\")\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "save_prompt(CALL_PROMPT, [], CALL_PROMPT_FILE_NAME)\n",
    "save_prompt(SUMMARIZATION_PROMPT, [], CALL_SUMMARIZATION_PROMPT_FILENAME)\n",
    "\n",
    "\n",
    "class CallDataProcessor:\n",
    "\n",
    "    def __init__(self, model_name, summarization_prompt_path, classifier_prompt_path):\n",
    "        self.summarization_prompt = load_prompt(summarization_prompt_path)\n",
    "        self.classifier_prompt = load_prompt(classifier_prompt_path)\n",
    "        self.model_name = model_name \n",
    "\n",
    "    def process_input(self, input_data):\n",
    "        try:\n",
    "\n",
    "            llm = ChatOpenAI(model=self.model_name, temperature=0)\n",
    "            llm_json = ChatOpenAI(model=self.model_name, temperature=0, model_kwargs={'response_format': {\"type\": \"json_object\"}})\n",
    "            \n",
    "            # Create the classifier and summary chains\n",
    "            classifier_chain = self.classifier_prompt | llm_json | SimpleJsonOutputParser()\n",
    "            classifier_result = classifier_chain.invoke(input_data)\n",
    "            \n",
    "            summary_chain = self.summarization_prompt | llm\n",
    "            summary_result = summary_chain.invoke(input_data).content\n",
    "            \n",
    "            # Structure the results\n",
    "            result = {\n",
    "                \"Transcript\": input_data,\n",
    "                \"Summary\": summary_result,\n",
    "                \"Issue\": classifier_result['Issue'],\n",
    "                \"Issue Summary\": classifier_result['Issue Summary'],\n",
    "                \"Severity\": classifier_result['Severity'],\n",
    "                \"Clinician to Contact\": classifier_result['Clinician to Contact']\n",
    "            }\n",
    "        \n",
    "            return result\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "classifier_prompt_path= CALL_PROMPT_FILE_NAME\n",
    "summarization_prompt_path = CALL_SUMMARIZATION_PROMPT_FILENAME\n",
    "\n",
    "processor = CallDataProcessor(DEFAULT_OPENAI_MODEL_NAME, summarization_prompt_path, classifier_prompt_path)\n",
    "\n",
    "\n",
    "# Use as Example\n",
    "\n",
    "# input_text = \"A woman at the library collapsed and isn't breathing. We need an ambulance right away!\"\n",
    "# processor.process_input(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**LLM TESTING**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "def evaluation_chain(\n",
    "    input_data,\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    output_parser=StrOutputParser()\n",
    "):\n",
    "    eval_system_prompt = \"\"\"You are an assistant that evaluates whether an input containing a patient transcript and related information has all required fields present and non-empty.\n",
    "    The input data should include the following keys: Transcript, Summary, Issue, Issue Summary, Severity, Clinician to Contact.\n",
    "    \"\"\"\n",
    "\n",
    "    eval_user_message = f\"\"\"Please evaluate the following input data to ensure all required fields are present and contain valid, non-empty data:\n",
    "    Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    Transcript: {input_data.get('Transcript', '')}\n",
    "    Summary: {input_data.get('Summary', '')}\n",
    "    Issue: {input_data.get('Issue', '')}\n",
    "    Issue Summary: {input_data.get('Issue Summary', '')}\n",
    "    Severity: {input_data.get('Severity', '')}\n",
    "    Clinician to Contact: {input_data.get('Clinician to Contact', '')}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "    Check if the following fields are present and contains valid, non-empty data:\n",
    "    - Transcript\n",
    "    - Summary\n",
    "    - Issue\n",
    "    - Issue Summary\n",
    "    - Severity\n",
    "    - Clinician to Contact\n",
    "\n",
    "\n",
    "    Respond with 'Y' if all fields are present and non-empty, 'N' if any field is missing, empty, or if the field contains the keyword \"Invalid\".\n",
    "    \"\"\"\n",
    "\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", eval_system_prompt),\n",
    "        (\"human\", eval_user_message),\n",
    "    ])\n",
    "\n",
    "    return eval_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prompt_testing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prompt_testing.py\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "def evaluation_chain(\n",
    "    input_data,\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    output_parser=StrOutputParser()\n",
    "):\n",
    "    eval_system_prompt = \"\"\"You are an assistant that evaluates whether an input containing a patient transcript and related information has all required fields present and non-empty.\n",
    "    The input data should include the following keys: Transcript, Summary, Issue, Issue Summary, Severity, Clinician to Contact.\n",
    "    \"\"\"\n",
    "\n",
    "    eval_user_message = f\"\"\"Please evaluate the following input data to ensure all required fields are present and contain valid, non-empty data:\n",
    "    Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    Transcript: {input_data.get('Transcript', '')}\n",
    "    Summary: {input_data.get('Summary', '')}\n",
    "    Issue: {input_data.get('Issue', '')}\n",
    "    Issue Summary: {input_data.get('Issue Summary', '')}\n",
    "    Severity: {input_data.get('Severity', '')}\n",
    "    Clinician to Contact: {input_data.get('Clinician to Contact', '')}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "    Check if the following fields are present and contains valid, non-empty data:\n",
    "    - Transcript\n",
    "    - Summary\n",
    "    - Issue\n",
    "    - Issue Summary\n",
    "    - Severity\n",
    "    - Clinician to Contact\n",
    "\n",
    "\n",
    "    Respond with 'Y' if all fields are present and non-empty, 'N' if any field is missing, empty, or if the field contains the keyword \"Invalid\".\n",
    "    \"\"\"\n",
    "\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", eval_system_prompt),\n",
    "        (\"human\", eval_user_message),\n",
    "    ])\n",
    "\n",
    "    return eval_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "bad_example = {\n",
    "    'Transcript': \"\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(bad_example)\n",
    "response = eval_chain.invoke({})\n",
    "print(response)\n",
    "assert response == \"N\", f\"Expected response to be 'N', but it was not.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "bad_example2 = {\n",
    "    'Transcript': \"Invalid\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(bad_example2)\n",
    "response2 = eval_chain.invoke({})\n",
    "print(response2)\n",
    "assert response == \"N\", f\"Expected response to be 'N', but it was not.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    }
   ],
   "source": [
    "good_example = {\n",
    "    'Transcript': \"A woman at the library collapsed and isn't breathing. We need an ambulance right away!\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(good_example)\n",
    "response = eval_chain.invoke({})\n",
    "print(response)\n",
    "assert response == \"Y\", f\"Expected response to be 'N', but it was not.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    }
   ],
   "source": [
    "good_example = \\\n",
    "{'Transcript': \"Please hurry, she's unconscious on the floor! I tried checking her pulse, but there's nothing. We've already called 911, but she needs help now! I think she might have hit her head when she fell. Is there anything we can do while we wait for the ambulance?\",\n",
    "'Summary': 'Urgent situation: unconscious woman, no pulse, possible head injury, awaiting ambulance.',\n",
    "'Issue': 'Unconscious patient, possible head injury',\n",
    "'Issue Summary': 'Unconscious with potential head injury',\n",
    "'Severity': 'High',\n",
    "'Clinician to Contact': 'general'}\n",
    "eval_chain = evaluation_chain(good_example)\n",
    "response = eval_chain.invoke({})\n",
    "print(response)\n",
    "assert response == \"Y\", f\"Expected response to be 'N', but it was not.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "N\n",
      "Y\n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from prompt_testing import evaluation_chain\n",
    "\n",
    "bad_example = {\n",
    "    'Transcript': \"\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(bad_example)\n",
    "response = eval_chain.invoke({})\n",
    "print(response)\n",
    "assert response == \"N\", f\"Expected response to be 'N', but it was not.\"\n",
    "\n",
    "bad_example2 = {\n",
    "    'Transcript': \"Invalid\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(bad_example2)\n",
    "response2 = eval_chain.invoke({})\n",
    "print(response2)\n",
    "assert response2 == \"N\", f\"Expected response to be 'N', but it was not.\"\n",
    "\n",
    "good_example1 = {\n",
    "    'Transcript': \"A woman at the library collapsed and isn't breathing. We need an ambulance right away!\",\n",
    "    'Summary': 'A woman at the library has collapsed and is currently not breathing, prompting an urgent call for an ambulance.',\n",
    "    'Issue': 'A woman collapsed and is not breathing at the library.',\n",
    "    'Issue Summary': 'Woman collapsed, not breathing, requires immediate help.',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(good_example1)\n",
    "response1 = eval_chain.invoke({})\n",
    "print(response1)\n",
    "assert response1 == \"Y\", f\"Expected response to be 'Y', but it was not.\"\n",
    "\n",
    "good_example2 = {\n",
    "    'Transcript': \"Please hurry, she's unconscious on the floor! I tried checking her pulse, but there's nothing. We've already called 911, but she needs help now! I think she might have hit her head when she fell. Is there anything we can do while we wait for the ambulance?\",\n",
    "    'Summary': 'Urgent situation: unconscious woman, no pulse, possible head injury, awaiting ambulance.',\n",
    "    'Issue': 'Unconscious patient, possible head injury',\n",
    "    'Issue Summary': 'Unconscious with potential head injury',\n",
    "    'Severity': 'High',\n",
    "    'Clinician to Contact': 'general'\n",
    "}\n",
    "\n",
    "eval_chain = evaluation_chain(good_example2)\n",
    "response2 = eval_chain.invoke({})\n",
    "print(response2)\n",
    "assert response2 == \"Y\", f\"Expected response to be 'Y', but it was not.\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Transcript = \\\n",
    "\"\"\"\n",
    "Call Handler: \"999 Emergency, which service do you require?\"\n",
    "Patient: \"A woman at the library collapsed and isn't breathing. We need an ambulance right away!\"\n",
    "Call Handler: \"I understand, sir. Can you please provide the address or location of the library?\"\n",
    "Patient: \"It's the central library on High Street in Birmingham.\"\n",
    "Call Handler: \"Thank you. Help is on its way. Is there anyone currently providing first aid or CPR to the woman?\"\n",
    "Patient: \"Yes, there's a trained first aider here attending to her.\"\n",
    "Call Handler: \"That's excellent. Please reassure the first aider that help is imminent and to continue their assistance until the ambulance arrives. We're dispatching help as quickly as possible.\"\n",
    "Patient: \"Thank you, please hurry.\"\n",
    "Call Handler: \"We're doing everything we can to expedite assistance. Can you confirm if there are any hazards or obstacles that might impede access to the patient?\"\n",
    "Patient: \"No, the area is clear. Please hurry, though.\"\n",
    "Call Handler: \"Help is on the way. Stay on the line with me until they arrive. Is there anything else you need assistance with?\"\n",
    "Patient: \"No, that's all. Please hurry.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
